{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import os\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import layers\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D, ZeroPadding2D\n",
    "from keras import applications\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.applications import VGG16, ResNet50\n",
    "from keras.optimizers import RMSprop,Adam    \n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(\"train\")\n",
    "shuffle(filenames)\n",
    "age=[]  #Children (1-14) CLASS 0;Youth (14-25) CLASS 1;ADULTS (25-40) CLASS 2;Middle age (40-60) CLASS 3\n",
    "         #Very Old (>60) CLASS 4\n",
    "gender=[] #0=male ;1=female\n",
    "\n",
    "for filename in filenames:\n",
    "    label_1=filename.split('_')[0]\n",
    "    label_1 = int(label_1)\n",
    "    if label_1 <= 14:\n",
    "        age.append(str(0))\n",
    "    if (label_1>14) and (label_1<=25):\n",
    "        age.append(str(1))\n",
    "    if (label_1>25) and (label_1<40):\n",
    "        age.append(str(2))\n",
    "    if (label_1>=40) and (label_1<60):\n",
    "        age.append(str(3))\n",
    "    if label_1>=60:\n",
    "        age.append(str(4))\n",
    "   \n",
    "for filename in filenames:\n",
    "    label_2=filename.split('_')[1]\n",
    "    label_2 = int(label_2)\n",
    "    if label_2 == 0:\n",
    "        gender.append(str(0))\n",
    "    if label_2 == 1:\n",
    "        gender.append(str(1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8_1_0_20170109204542015.jpg.chip.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1_2_20161219201453804.jpg.chip.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18_0_3_20170104230349313.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22_1_3_20170119163028157.jpg.chip.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26_1_1_20170112213007903.jpg.chip.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename age gender\n",
       "0   8_1_0_20170109204542015.jpg.chip.jpg   0      1\n",
       "1   1_1_2_20161219201453804.jpg.chip.jpg   0      1\n",
       "2  18_0_3_20170104230349313.jpg.chip.jpg   1      0\n",
       "3  22_1_3_20170119163028157.jpg.chip.jpg   1      1\n",
       "4  26_1_1_20170112213007903.jpg.chip.jpg   2      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\n",
    "    'filename':filenames,\n",
    "    'age':age,\n",
    "    'gender':gender\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_row = 32\n",
    "img_col = 32\n",
    "epochs = 30\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\TOOLS\\Anaconda\\envs\\tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From D:\\TOOLS\\Anaconda\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pre_trained_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_row,img_col,3)) #taking pretrained weights;top layer chopped off as i am going to use it of my own;\n",
    "    \n",
    "for layer in pre_trained_model.layers[:15]:\n",
    "    layer.trainable = False  \n",
    "\n",
    "for layer in pre_trained_model.layers[15:]:\n",
    "    layer.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = pre_trained_model.output #output of vgg16 last layer taken as input here\n",
    "top_model = Flatten()(top_model)\n",
    "layer_1 = Dense(1024,activation='relu')(top_model)\n",
    "layer_2= Dense(1024,activation='relu')(top_model)\n",
    "#layer_1 = Dense(128,activation='relu')(layer_1)\n",
    "layer_1 = Dropout(0.5)(layer_1)\n",
    "layer_2 = Dropout(0.5)(layer_2)\n",
    "out_1 = Dense(5,activation='softmax',name='out_1')(layer_1) #for age\n",
    "out_2 = Dense(1,activation='sigmoid',name='out_2')(layer_2) #for gender\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = pre_trained_model.input ,outputs=out_2) #use out_1 for age and out_2 for gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21337\n",
      "2371\n"
     ]
    }
   ],
   "source": [
    "train_df, validate_df = train_test_split(df, test_size=0.1)#df is the dataframe;train_test_split er prothom\n",
    "train_df = train_df.reset_index()                #arguement ta has to be a pd.dataframe,np.array or list\n",
    "validate_df = validate_df.reset_index() #ekdom shamner index gula 0 theke shuru hoi age jai thakuk\n",
    "                                        #test_size determines kottuk test set e thakbe\n",
    "# validate_df = validate_df.sample(n=100).reset_index() # use for fast testing code purpose\n",
    "# train_df = train_df.sample(n=1800).reset_index() # use for fast testing code purpose\n",
    "\n",
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "\n",
    "print(total_train)\n",
    "print(total_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21337 validated image filenames belonging to 2 classes.\n",
      "Found 2371 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, \n",
    "    \"train\", \n",
    "    x_col='filename',\n",
    "    y_col='gender',\n",
    "    class_mode='binary',                    #'multi_output'],\n",
    "    target_size=(img_row, img_col),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    \"train\", #duitai training file theke kintu\n",
    "    x_col='filename',\n",
    "    y_col='gender',\n",
    "    class_mode='binary',\n",
    "    target_size=(img_row, img_col),\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=.0001),                              #{'out_1':'adam','out_2':'adam'}, \n",
    "              loss='binary_crossentropy',\n",
    "              metrics =['accuracy']                           #{'out_1':\"accuracy\",'out_2':\"accuracy\"}\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop,Adam    #import activation function that you need\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau \n",
    "\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', #helps to monitor if val_loss;if it doesn't reduce after 5 epochs, the learning rate will be decreased and checked again in the same way;this will be done upto lr=.001\n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.2, \n",
    "                                            min_lr=0.0001)\n",
    "\n",
    "callbacks=[learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\TOOLS\\Anaconda\\envs\\tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/30\n",
      "166/166 [==============================] - 65s 394ms/step - loss: 0.5857 - accuracy: 0.6929 - val_loss: 0.5464 - val_accuracy: 0.7517\n",
      "Epoch 2/30\n",
      "166/166 [==============================] - 68s 409ms/step - loss: 0.5530 - accuracy: 0.7178 - val_loss: 0.5205 - val_accuracy: 0.7570\n",
      "Epoch 3/30\n",
      "166/166 [==============================] - 68s 412ms/step - loss: 0.5365 - accuracy: 0.7323 - val_loss: 0.4776 - val_accuracy: 0.7543\n",
      "Epoch 4/30\n",
      "166/166 [==============================] - 69s 414ms/step - loss: 0.5290 - accuracy: 0.7362 - val_loss: 0.4838 - val_accuracy: 0.7530\n",
      "Epoch 5/30\n",
      "166/166 [==============================] - 69s 413ms/step - loss: 0.5236 - accuracy: 0.7396 - val_loss: 0.4922 - val_accuracy: 0.7543\n",
      "Epoch 6/30\n",
      "166/166 [==============================] - 69s 414ms/step - loss: 0.5210 - accuracy: 0.7424 - val_loss: 0.4568 - val_accuracy: 0.7780\n",
      "Epoch 7/30\n",
      "166/166 [==============================] - 69s 415ms/step - loss: 0.5157 - accuracy: 0.7421 - val_loss: 0.5386 - val_accuracy: 0.7726\n",
      "Epoch 8/30\n",
      "166/166 [==============================] - 69s 414ms/step - loss: 0.5169 - accuracy: 0.7414 - val_loss: 0.4949 - val_accuracy: 0.7744\n",
      "Epoch 9/30\n",
      "166/166 [==============================] - 69s 414ms/step - loss: 0.5123 - accuracy: 0.7486 - val_loss: 0.5470 - val_accuracy: 0.7436\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/30\n",
      "166/166 [==============================] - 68s 411ms/step - loss: 0.5000 - accuracy: 0.7556 - val_loss: 0.4688 - val_accuracy: 0.7918\n",
      "Epoch 11/30\n",
      "166/166 [==============================] - 69s 416ms/step - loss: 0.4933 - accuracy: 0.7600 - val_loss: 0.4801 - val_accuracy: 0.7793\n",
      "Epoch 12/30\n",
      "166/166 [==============================] - 71s 428ms/step - loss: 0.4928 - accuracy: 0.7598 - val_loss: 0.4467 - val_accuracy: 0.7650\n",
      "Epoch 13/30\n",
      "166/166 [==============================] - 70s 419ms/step - loss: 0.4882 - accuracy: 0.7620 - val_loss: 0.3689 - val_accuracy: 0.7842\n",
      "Epoch 14/30\n",
      "166/166 [==============================] - 70s 424ms/step - loss: 0.4881 - accuracy: 0.7653 - val_loss: 0.4427 - val_accuracy: 0.7811\n",
      "Epoch 15/30\n",
      "166/166 [==============================] - 70s 424ms/step - loss: 0.4886 - accuracy: 0.7591 - val_loss: 0.5018 - val_accuracy: 0.7784\n",
      "Epoch 16/30\n",
      "166/166 [==============================] - 66s 400ms/step - loss: 0.4882 - accuracy: 0.7610 - val_loss: 0.4441 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 17/30\n",
      "166/166 [==============================] - 66s 396ms/step - loss: 0.4886 - accuracy: 0.7632 - val_loss: 0.4318 - val_accuracy: 0.7882\n",
      "Epoch 18/30\n",
      "166/166 [==============================] - 72s 432ms/step - loss: 0.4874 - accuracy: 0.7621 - val_loss: 0.4394 - val_accuracy: 0.7807\n",
      "Epoch 19/30\n",
      "166/166 [==============================] - 71s 430ms/step - loss: 0.4851 - accuracy: 0.7635 - val_loss: 0.4118 - val_accuracy: 0.7829\n",
      "Epoch 20/30\n",
      "166/166 [==============================] - 68s 408ms/step - loss: 0.4815 - accuracy: 0.7667 - val_loss: 0.3959 - val_accuracy: 0.7847\n",
      "Epoch 21/30\n",
      "166/166 [==============================] - 67s 403ms/step - loss: 0.4895 - accuracy: 0.7627 - val_loss: 0.4510 - val_accuracy: 0.7824\n",
      "Epoch 22/30\n",
      "166/166 [==============================] - 67s 404ms/step - loss: 0.4842 - accuracy: 0.7643 - val_loss: 0.4750 - val_accuracy: 0.7784\n",
      "Epoch 23/30\n",
      "166/166 [==============================] - 69s 413ms/step - loss: 0.4865 - accuracy: 0.7611 - val_loss: 0.4254 - val_accuracy: 0.7869\n",
      "Epoch 24/30\n",
      "166/166 [==============================] - 69s 418ms/step - loss: 0.4793 - accuracy: 0.7690 - val_loss: 0.3874 - val_accuracy: 0.7820\n",
      "Epoch 25/30\n",
      "166/166 [==============================] - 72s 433ms/step - loss: 0.4820 - accuracy: 0.7645 - val_loss: 0.4577 - val_accuracy: 0.7856\n",
      "Epoch 26/30\n",
      "166/166 [==============================] - 66s 399ms/step - loss: 0.4816 - accuracy: 0.7686 - val_loss: 0.4636 - val_accuracy: 0.7878\n",
      "Epoch 27/30\n",
      "166/166 [==============================] - 68s 409ms/step - loss: 0.4811 - accuracy: 0.7653 - val_loss: 0.4707 - val_accuracy: 0.7829\n",
      "Epoch 28/30\n",
      "166/166 [==============================] - 68s 407ms/step - loss: 0.4828 - accuracy: 0.7669 - val_loss: 0.4726 - val_accuracy: 0.7869\n",
      "Epoch 29/30\n",
      "166/166 [==============================] - 68s 410ms/step - loss: 0.4833 - accuracy: 0.7652 - val_loss: 0.4334 - val_accuracy: 0.7864\n",
      "Epoch 30/30\n",
      "166/166 [==============================] - 67s 405ms/step - loss: 0.4786 - accuracy: 0.7703 - val_loss: 0.3500 - val_accuracy: 0.7856\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"gender_detection_60epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"gender_prediction_50.h5\",\n",
    "                             monitor=\"val_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 15,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, min_delta = 0.0001)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "166/166 [==============================] - 64s 385ms/step - loss: 0.4797 - accuracy: 0.7716 - val_loss: 0.4647 - val_accuracy: 0.7869\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78689, saving model to gender_prediction_50.h5\n",
      "Epoch 2/30\n",
      "166/166 [==============================] - 68s 410ms/step - loss: 0.4861 - accuracy: 0.7620 - val_loss: 0.4919 - val_accuracy: 0.7807\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78689\n",
      "Epoch 3/30\n",
      "166/166 [==============================] - 68s 410ms/step - loss: 0.4803 - accuracy: 0.7700 - val_loss: 0.5526 - val_accuracy: 0.7842\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.78689\n",
      "Epoch 4/30\n",
      "166/166 [==============================] - 68s 412ms/step - loss: 0.4771 - accuracy: 0.7699 - val_loss: 0.4375 - val_accuracy: 0.7856\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.78689\n",
      "Epoch 5/30\n",
      "166/166 [==============================] - 70s 420ms/step - loss: 0.4792 - accuracy: 0.7697 - val_loss: 0.5140 - val_accuracy: 0.7869\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.78689 to 0.78689, saving model to gender_prediction_50.h5\n",
      "Epoch 6/30\n",
      "166/166 [==============================] - 69s 416ms/step - loss: 0.4772 - accuracy: 0.7679 - val_loss: 0.5264 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.78689\n",
      "Epoch 7/30\n",
      "166/166 [==============================] - 68s 410ms/step - loss: 0.4772 - accuracy: 0.7686 - val_loss: 0.4084 - val_accuracy: 0.7922\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.78689 to 0.79224, saving model to gender_prediction_50.h5\n",
      "Epoch 8/30\n",
      "166/166 [==============================] - 70s 419ms/step - loss: 0.4769 - accuracy: 0.7718 - val_loss: 0.4384 - val_accuracy: 0.7869\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.79224\n",
      "Epoch 9/30\n",
      "166/166 [==============================] - 69s 413ms/step - loss: 0.4756 - accuracy: 0.7695 - val_loss: 0.3721 - val_accuracy: 0.7971\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.79224 to 0.79715, saving model to gender_prediction_50.h5\n",
      "Epoch 10/30\n",
      "166/166 [==============================] - 66s 397ms/step - loss: 0.4735 - accuracy: 0.7717 - val_loss: 0.4218 - val_accuracy: 0.7842\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.79715\n",
      "Epoch 11/30\n",
      "166/166 [==============================] - 66s 400ms/step - loss: 0.4733 - accuracy: 0.7706 - val_loss: 0.4324 - val_accuracy: 0.7789\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.79715\n",
      "Epoch 12/30\n",
      "166/166 [==============================] - 68s 407ms/step - loss: 0.4745 - accuracy: 0.7697 - val_loss: 0.4491 - val_accuracy: 0.7909\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.79715\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 13/30\n",
      "166/166 [==============================] - 67s 402ms/step - loss: 0.4722 - accuracy: 0.7725 - val_loss: 0.5331 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.79715\n",
      "Epoch 14/30\n",
      "166/166 [==============================] - 70s 421ms/step - loss: 0.4706 - accuracy: 0.7719 - val_loss: 0.4463 - val_accuracy: 0.7882\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.79715\n",
      "Epoch 15/30\n",
      "166/166 [==============================] - 67s 405ms/step - loss: 0.4723 - accuracy: 0.7725 - val_loss: 0.4706 - val_accuracy: 0.7838\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.79715\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "Epoch 16/30\n",
      "166/166 [==============================] - 66s 399ms/step - loss: 0.4720 - accuracy: 0.7736 - val_loss: 0.4815 - val_accuracy: 0.7780\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.79715\n",
      "Epoch 17/30\n",
      "166/166 [==============================] - 65s 394ms/step - loss: 0.4726 - accuracy: 0.7691 - val_loss: 0.4378 - val_accuracy: 0.7856\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.79715\n",
      "Epoch 18/30\n",
      "166/166 [==============================] - 66s 398ms/step - loss: 0.4705 - accuracy: 0.7729 - val_loss: 0.4306 - val_accuracy: 0.7780\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.79715\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "Epoch 19/30\n",
      "166/166 [==============================] - 68s 409ms/step - loss: 0.4697 - accuracy: 0.7772 - val_loss: 0.4088 - val_accuracy: 0.7824\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.79715\n",
      "Epoch 20/30\n",
      "166/166 [==============================] - 66s 395ms/step - loss: 0.4740 - accuracy: 0.7695 - val_loss: 0.4709 - val_accuracy: 0.7812\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.79715\n",
      "Epoch 21/30\n",
      "166/166 [==============================] - 65s 393ms/step - loss: 0.4760 - accuracy: 0.7702 - val_loss: 0.3753 - val_accuracy: 0.7815\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.79715\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "Epoch 22/30\n",
      "166/166 [==============================] - 65s 393ms/step - loss: 0.4719 - accuracy: 0.7747 - val_loss: 0.4128 - val_accuracy: 0.7847\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.79715\n",
      "Epoch 23/30\n",
      "166/166 [==============================] - 66s 395ms/step - loss: 0.4712 - accuracy: 0.7727 - val_loss: 0.4559 - val_accuracy: 0.7838\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.79715\n",
      "Epoch 24/30\n",
      "166/166 [==============================] - 65s 394ms/step - loss: 0.4708 - accuracy: 0.7756 - val_loss: 0.4317 - val_accuracy: 0.7807\n",
      "Restoring model weights from the end of the best epoch\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.79715\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
